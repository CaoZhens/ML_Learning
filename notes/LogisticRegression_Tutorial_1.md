# 逻辑回归（1）解决二分类问题的思路

## 从回归问题到二分类问题

前面介绍的线性回归模型，用于连续值预测；
**提问：对于0-1问题（二分类问题），继续使用线性回归模型是否合适呢？** 
让我们来看一个直观举例：

对比两图我们发现，x轴正向远端的样本点会干扰模型的判决平面，因此直接使用线性回归模型处理二分类问题是不合适的。
**思考：能否找到一个函数，可以将连续值映射为0-1值？这样我们就可以利用线性回归与该函数的叠加，处理二分类问题了**。

## Sigmoid/Logistic Function

$$ g(z) = \frac{1}{1+e^{-z}} = \frac{e^z}{1+e^z}$$

函数图像为：

该函数的一个重要特性，证明请见本节附录
$$ g(z)^{\prime} = g(z)(1-g(z))$$

## 逻辑回归建模

逻辑回归模型如下：
基于单个样本：
$$h_\theta(\mathbf{x}) = g(\theta^T\mathbf{x}) = \frac{1}{1+e^{-\theta^T\mathbf{x}}}$$

基于多个样本：
$$h_\theta(\mathbf{X}) = g(\mathbf{X}\theta) = \frac{1}{1+e^{-\mathbf{X}\theta}}$$

备注：如果不明白为什么从$\theta^T\mathbf{x}$ 到 $\mathbf{X}\theta$，请[到这里](LinearRegression_Tutorial_1.md)重新看一遍$\mathbf{X}$的定义。

下一篇笔记将具体讨论逻辑回归模型的求解过程。




