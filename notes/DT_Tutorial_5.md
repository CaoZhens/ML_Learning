# 决策树的两要素与函数本质

## 决策树的两要素

**利用决策树对训练数据建模，其实质就是利用ID3/C4.5/CART等算法对训练数据集作划分，树结构就是划分的具象呈现方式**。因此，决策树的两要素，**结构**必占其一。

此外，**划分不是目的，对测试集的预测结果才是**，因此每个叶子节点都会被映射至一个输出值。将该输出值称为**叶子权值**，记第$j$个叶子节点的叶子权值为为$w_j$。

**总结：决策树的两要素即结构和叶子权值**，不妨形式化定义为
$$ DecisionTree = Tree's Structure + \{w_j\} $$

## 决策树的函数本质

假设已经构造好一棵决策树：  
考虑某个样本$\mathbf{x}^i$，输入决策树后，会按决策树的划分方式逐级划分直至叶子节点，并将该叶子节点的叶子权值作为输出值。记样本$\mathbf{x}^i$所属叶子节点为$j = q(\mathbf{x}^i)$，叶子权值为$w_j = w_{q(\mathbf{x}^i)}$

**总结：决策树的本质是以$\mathbf{x}^i$为输入，$w_{q(\mathbf{x}^i)}$为输出的函数**，记为：
$$f(\mathbf{x}^i) = w_{q(\mathbf{x}^i)}$$