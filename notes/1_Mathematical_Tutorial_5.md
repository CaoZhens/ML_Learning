# 机器学习的数学基础[5] - 信息论基础

## 信息熵

对离散变量：
$$H(X) = -\sum_i P(X_i) \log{P(X_i)}$$
对连续变量，求和变积分：

为简化内容，以下均以离散变量为例。

## 联合熵
$$H(X,Y) = -\sum_{x,y} P(x,y) \log{P(x,y)}$$

## 条件熵

## 交叉熵

## 互信息