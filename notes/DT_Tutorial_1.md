# 决策树算法概述

## 决策树建模的基本思想
* 树型结构（“倒着的树”，最上方是根节点，最下方是叶子节点）
* 节点的每一次分裂代表对数据集的划分
    * 一般情况下，每次只利用一个特征
    * 可以选择二分，或者根据该特征的每个可能值划分
* 决策树建模，或者说数据集划分的原则是：将无序数据变得更加有序

## 利用信息论量化数据集划分

**决策树建模的核心：针对每一个节点，找到最佳分裂方式，从而建立整棵决策树。**
利用信息论的基本知识，评价数据集划分的优劣。主要包括以下三种算法：
1. ID3:利用**信息增益**衡量数据集划分
2. C4.5:利用**信息增益比**衡量数据集划分
3. CART:利用**gini系数**衡量数据集划分
关于信息论及信息增益、信息增益比、gini系数等概念，请参考机器学习的数学基础部分。

## 决策树的过拟合

由于决策树的建模是以训练数据为基础的归纳型算法，因此有可能在测试数据上表现不佳。
因此需要采取方法，提高决策树的泛化能力，称之为**剪枝**。