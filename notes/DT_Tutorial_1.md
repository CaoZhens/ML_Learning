# 决策树概述

## 决策树建模的基本思想
* 树型结构（“倒着的树”，最上方是根节点，最下方是叶子节点）
* 根节点的每一次分裂，即代表对数据集的一次划分
* 满足*一定条件*时，不再对子树的节点进行划分，该节点成为叶节点
* 每个叶节点会承载若干数据，并将这些数据映射成一个统一的输出值
    * 针对离散型数据样本，可以采用“少数服从多数”的表决原则，映射成最多数样本的输出值
    * 针对连续型数据样本，可以计算均值，将均值映射成输出值

## 如何构建决策树结构
从上面的描述可知，**结构**是决策树的核心。构建决策树结构，即划分数据集。
### 一般原则
* 构建决策树结构，或者说划分数据集的原则是：将无序数据变得更加有序
* 一般情况下，每次只选取一个特征划分数据集
* 可以选择二分，也可以根据该特征的每个可能值划分
### 评价方式
利用信息论概念，评价数据集划分的优劣。主要包括以下三种算法：
1. ID3:利用**信息增益**衡量数据集划分
2. C4.5:利用**信息增益比**衡量数据集划分
3. CART:利用**gini系数**衡量数据集划分
关于信息论及信息增益、信息增益比、gini系数等概念，请参考机器学习的数学基础部分。

## 决策树的过拟合

由于决策树的建模是以训练数据为基础的归纳型算法，因此有可能在测试数据上表现不佳。
因此需要采取方法，提高决策树的泛化能力，称之为**剪枝**。