# 机器学习笔记

本项目用于记录学习笔记、代码及其它内容

## 访问之前

**如何浏览笔记**

由于笔记中包含大量LaTeX公式，而GitHub Flavored Markdown（GFM）不支持LaTex，因此直接浏览会看到大量乱码
建议使用**Chrome浏览器**并安装扩展**GitHub with MathJax**，可以解决80%以上的乱码问题，其余乱码将随项目完善，逐渐进行解决

## 主要内容

### 一、机器学习的数学基础

[机器学习的数学基础[1] - 自然底数e](./notes/1_Mathematical_Tutorial_1.md)

机器学习的数学基础[2] - Gamma函数的意义

机器学习的数学基础[3] - Taylor展式及其应用

### 二、线性回归／最小二乘法／梯度下降法

#### 模型篇

[线性回归[1] - 模型建立](./notes/LinearRegression_Tutorial_1.md)

[线性回归[2] - 利用最小二乘法与梯度下降法求解模型](./notes/LinearRegression_Tutorial_2.md)

线性回归的扩展[1] - 对特征做扩展 - 多项式回归Polynomial Regression

线性回归的扩展[2] - 损失函数引入Normalization - Lasso/Ridge/ElasticNet


#### 算法篇

批梯度下降与随机梯度下降

![image](https://github.com/CaoZhens/ML_Learning/blob/master/study/6_LinearRegression/pic/LinearR_GD_FittingCurve.gif) 

### 三、 Logistic回归与SoftMax回归

#### 模型篇

Logistic Regression - 二分类器

SoftMax Regression - 多分类器

逻辑回归与最大熵模型

#### 算法篇

![image](https://github.com/CaoZhens/ML_Learning/blob/master/study/7_LogisticRegression/pic/LogisticR_GD_FittingCurve.gif) 

### 四、 决策树

ID3 / C4.5

CART

Pruning

### 五、 Ensemble

Bagging

Boosting

### 六、 SVM

... ...